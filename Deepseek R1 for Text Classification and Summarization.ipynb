{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0754c1a5",
   "metadata": {},
   "source": [
    "## Detailed Article Explaination\n",
    "\n",
    "The detailed code explanation for this article is available at the following link:\n",
    "\n",
    "https://www.daniweb.com/programming/computer-science/tutorials/542973/benchmarking-deepseek-r1-for-text-classification-and-summarization\n",
    "\n",
    "\n",
    "For my other articles for Daniweb.com, please see this link:\n",
    "\n",
    "https://www.daniweb.com/members/1235222/usmanmalik57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df48a7b",
   "metadata": {},
   "source": [
    "## Installing and Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cb0c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub==0.24.7 in c:\\users\\usman\\anaconda3\\lib\\site-packages (0.24.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\usman\\anaconda3\\lib\\site-packages (from huggingface_hub==0.24.7) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from huggingface_hub==0.24.7) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from huggingface_hub==0.24.7) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from huggingface_hub==0.24.7) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\usman\\anaconda3\\lib\\site-packages (from huggingface_hub==0.24.7) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from huggingface_hub==0.24.7) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from huggingface_hub==0.24.7) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\usman\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub==0.24.7) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.24.7) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.24.7) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.24.7) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.24.7) (2023.7.22)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\usman\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\usman\\anaconda3\\lib\\site-packages (from rouge-score) (2.0.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\usman\\anaconda3\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\usman\\anaconda3\\lib\\site-packages (from rouge-score) (1.24.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\usman\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\usman\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usman\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\usman\\anaconda3\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\usman\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\usman\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\usman\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub==0.24.7\n",
    "!pip install rouge-score\n",
    "!pip install --upgrade openpyxl\n",
    "!pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ccc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e400e94",
   "metadata": {},
   "source": [
    "## Calling DeepSeek R1 Model Using Hugging Face Inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6868995",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.environ.get('HF_TOKEN') \n",
    "\n",
    "#deepseek-R1-distill endpoint\n",
    "#https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n",
    "deepseek_model_client = InferenceClient(\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    token=hf_token\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1806ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, system_role, user_query):\n",
    "    \n",
    "    response = model.chat_completion(\n",
    "    messages=[{\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_query}],\n",
    "    max_tokens=1000,\n",
    "    )\n",
    "         \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c172cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, I need to assign a sentiment to the movie review \"I like this movie a lot.\" Let\\'s break this down. The user expressed that they like the movie a lot, which indicates a positive feeling. Words like \"like\" and \"a lot\" are strong indicators of satisfaction. There\\'s no negative language here, and the enthusiasm is clear. So, the sentiment is definitely positive.\\n</think>\\n\\npositive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_role = \"Assign positive, negative, or neutral sentiment to the movie review. Return only a single word in your response\"\n",
    "user_query = \"I like this movie a lot\"\n",
    "output = make_prediction(deepseek_model_client,\n",
    "               system_role,\n",
    "               user_query)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e326ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "last_word = output.strip().split(\"\\n\")[-1].strip()\n",
    "print(last_word) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22475d33",
   "metadata": {},
   "source": [
    "## DeepSeek For Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0a823d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dataset download link\n",
    "## https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment?select=Tweets.csv\n",
    "\n",
    "dataset = pd.read_csv(r\"D:\\Datasets\\Tweets.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eedad4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_sentiment\n",
      "neutral     34\n",
      "positive    33\n",
      "negative    33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where 'airline_sentiment' or 'text' are NaN\n",
    "dataset = dataset.dropna(subset=['airline_sentiment', 'text'])\n",
    "\n",
    "# Remove rows where 'airline_sentiment' or 'text' are empty strings\n",
    "dataset = dataset[(dataset['airline_sentiment'].str.strip() != '') & (dataset['text'].str.strip() != '')]\n",
    "\n",
    "# Filter the DataFrame for each sentiment\n",
    "neutral_df = dataset[dataset['airline_sentiment'] == 'neutral']\n",
    "positive_df = dataset[dataset['airline_sentiment'] == 'positive']\n",
    "negative_df = dataset[dataset['airline_sentiment'] == 'negative']\n",
    "\n",
    "# Randomly sample records from each sentiment\n",
    "neutral_sample = neutral_df.sample(n=34)\n",
    "positive_sample = positive_df.sample(n=33)\n",
    "negative_sample = negative_df.sample(n=33)\n",
    "\n",
    "# Concatenate the samples into one DataFrame\n",
    "dataset = pd.concat([neutral_sample, positive_sample, negative_sample])\n",
    "\n",
    "# Reset index if needed\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print value counts\n",
    "print(dataset[\"airline_sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "620c8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, system_role, user_query):\n",
    "    \n",
    "    response = model.chat_completion(\n",
    "    messages=[{\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_query}],\n",
    "    max_tokens=1000,\n",
    "    )\n",
    "         \n",
    "    output =  response.choices[0].message.content\n",
    "    last_word = output.strip().split(\"\\n\")[-1].strip()\n",
    "    return last_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a3128eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tweet 1\n",
      "1 neutral\n",
      "Processing tweet 2\n",
      "2 neutral\n",
      "Processing tweet 3\n",
      "3 neutral\n",
      "Processing tweet 4\n",
      "4 neutral\n",
      "Processing tweet 5\n",
      "5 neutral\n",
      "Processing tweet 6\n",
      "6 neutral\n",
      "Processing tweet 7\n",
      "7 positive\n",
      "Processing tweet 8\n",
      "8 negative\n",
      "Processing tweet 9\n",
      "9 positive\n",
      "Processing tweet 10\n",
      "10 neutral\n",
      "Processing tweet 11\n",
      "11 neutral\n",
      "Processing tweet 12\n",
      "12 neutral\n",
      "Processing tweet 13\n",
      "13 neutral\n",
      "Processing tweet 14\n",
      "14 positive\n",
      "Processing tweet 15\n",
      "15 negative\n",
      "Processing tweet 16\n",
      "16 neutral\n",
      "Processing tweet 17\n",
      "17 neutral\n",
      "Processing tweet 18\n",
      "18 positive\n",
      "Processing tweet 19\n",
      "19 neutral\n",
      "Processing tweet 20\n",
      "20 negative\n",
      "Processing tweet 21\n",
      "21 negative\n",
      "Processing tweet 22\n",
      "22 neutral\n",
      "Processing tweet 23\n",
      "23 neutral\n",
      "Processing tweet 24\n",
      "24 neutral\n",
      "Processing tweet 25\n",
      "25 neutral\n",
      "Processing tweet 26\n",
      "26 neutral\n",
      "Processing tweet 27\n",
      "27 neutral\n",
      "Processing tweet 28\n",
      "28 neutral\n",
      "Processing tweet 29\n",
      "29 neutral\n",
      "Processing tweet 30\n",
      "30 positive\n",
      "Processing tweet 31\n",
      "31 neutral\n",
      "Processing tweet 32\n",
      "32 neutral\n",
      "Processing tweet 33\n",
      "33 neutral\n",
      "Processing tweet 34\n",
      "34 neutral\n",
      "Processing tweet 35\n",
      "35 positive\n",
      "Processing tweet 36\n",
      "36 positive\n",
      "Processing tweet 37\n",
      "37 positive\n",
      "Processing tweet 38\n",
      "38 positive\n",
      "Processing tweet 39\n",
      "39 positive\n",
      "Processing tweet 40\n",
      "40 positive\n",
      "Processing tweet 41\n",
      "41 positive\n",
      "Processing tweet 42\n",
      "42 positive\n",
      "Processing tweet 43\n",
      "43 Answer: positive\n",
      "Processing tweet 44\n",
      "44 positive\n",
      "Processing tweet 45\n",
      "45 positive\n",
      "Processing tweet 46\n",
      "46 positive\n",
      "Processing tweet 47\n",
      "47 **Sentiment:** negative\n",
      "Processing tweet 48\n",
      "48 positive\n",
      "Processing tweet 49\n",
      "49 positive\n",
      "Processing tweet 50\n",
      "50 positive\n",
      "Processing tweet 51\n",
      "51 positive\n",
      "Processing tweet 52\n",
      "52 positive\n",
      "Processing tweet 53\n",
      "53 positive\n",
      "Processing tweet 54\n",
      "54 positive\n",
      "Processing tweet 55\n",
      "55 **Answer: positive**\n",
      "Processing tweet 56\n",
      "56 positive\n",
      "Processing tweet 57\n",
      "57 positive\n",
      "Processing tweet 58\n",
      "58 positive\n",
      "Processing tweet 59\n",
      "59 positive\n",
      "Processing tweet 60\n",
      "60 positive\n",
      "Processing tweet 61\n",
      "61 positive\n",
      "Processing tweet 62\n",
      "62 positive\n",
      "Processing tweet 63\n",
      "63 positive\n",
      "Processing tweet 64\n",
      "64 positive\n",
      "Processing tweet 65\n",
      "65 positive\n",
      "Processing tweet 66\n",
      "66 positive\n",
      "Processing tweet 67\n",
      "67 positive\n",
      "Processing tweet 68\n",
      "68 negative\n",
      "Processing tweet 69\n",
      "69 negative\n",
      "Processing tweet 70\n",
      "70 negative\n",
      "Processing tweet 71\n",
      "71 negative\n",
      "Processing tweet 72\n",
      "72 negative\n",
      "Processing tweet 73\n",
      "73 neutral\n",
      "Processing tweet 74\n",
      "74 negative\n",
      "Processing tweet 75\n",
      "75 negative\n",
      "Processing tweet 76\n",
      "76 neutral\n",
      "Processing tweet 77\n",
      "77 negative\n",
      "Processing tweet 78\n",
      "78 negative\n",
      "Processing tweet 79\n",
      "79 negative\n",
      "Processing tweet 80\n",
      "80 negative\n",
      "Processing tweet 81\n",
      "81 negative\n",
      "Processing tweet 82\n",
      "82 negative\n",
      "Processing tweet 83\n",
      "83 negative\n",
      "Processing tweet 84\n",
      "84 positive\n",
      "Processing tweet 85\n",
      "85 negative\n",
      "Processing tweet 86\n",
      "86 negative\n",
      "Processing tweet 87\n",
      "87 negative\n",
      "Processing tweet 88\n",
      "88 negative\n",
      "Processing tweet 89\n",
      "89 negative\n",
      "Processing tweet 90\n",
      "90 negative\n",
      "Processing tweet 91\n",
      "91 negative\n",
      "Processing tweet 92\n",
      "92 negative\n",
      "Processing tweet 93\n",
      "93 negative\n",
      "Processing tweet 94\n",
      "94 negative\n",
      "Processing tweet 95\n",
      "95 negative\n",
      "Processing tweet 96\n",
      "96 negative\n",
      "Processing tweet 97\n",
      "97 negative\n",
      "Processing tweet 98\n",
      "98 negative\n",
      "Processing tweet 99\n",
      "99 negative\n",
      "Processing tweet 100\n",
      "100 negative\n",
      "Total exception count: 0\n"
     ]
    }
   ],
   "source": [
    "tweets_list = dataset[\"text\"].tolist()\n",
    "all_sentiments = []\n",
    "exceptions = 0\n",
    "\n",
    "for i, tweet in enumerate(tweets_list, 1):\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing tweet {i}\")\n",
    "        system_role = \"You are an expert in annotating tweets with positive, negative, and neutral emotions\"\n",
    "\n",
    "        user_query = (\n",
    "            f\"What is the sentiment expressed in the following tweet about an airline? \"\n",
    "            f\"Select sentiment value from positive, negative, or neutral. \"\n",
    "            f\"Return only the sentiment value in small letters.\\n\\n\"\n",
    "            f\"tweet: {tweet}\"\n",
    "        )\n",
    "\n",
    "        sentiment_value = predict_sentiment(deepseek_model_client, \n",
    "                                            system_role, \n",
    "                                            user_query)\n",
    "        all_sentiments.append({\n",
    "            'tweet_id': i,\n",
    "            'sentiment': sentiment_value\n",
    "        })\n",
    "        print(i, sentiment_value)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"===================\")\n",
    "        print(\"Exception occurred with Tweet:\", i, \"| Error:\", e)\n",
    "        exceptions += 1\n",
    "\n",
    "print(\"Total exception count:\", exceptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ecf7c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0    neutral\n",
       "1    neutral\n",
       "2    neutral\n",
       "3    neutral\n",
       "4    neutral\n",
       "..       ...\n",
       "95  negative\n",
       "96  negative\n",
       "97  negative\n",
       "98  negative\n",
       "99  negative\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = {\"positive\", \"negative\", \"neutral\"}\n",
    "\n",
    "result = []\n",
    "for string in all_sentiments:\n",
    "    for word in keywords:\n",
    "        if word in string[\"sentiment\"].lower(): \n",
    "            result.append({'sentiment':word})\n",
    "\n",
    "results_df = pd.DataFrame(result)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "854f37cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(results_df['sentiment'], dataset[\"airline_sentiment\"].iloc[:len(results_df)])\n",
    "print(f\"Overall Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f050b56d",
   "metadata": {},
   "source": [
    "## DeepSeek R1 For Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d5d9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>human_summary</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>theme</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>259</td>\n",
       "      <td>17650</td>\n",
       "      <td>The thinking goes that some of the ancient ice...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Nicholas St. Fleur</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Every Friday, we’ll offer a Trilobite talking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>259</td>\n",
       "      <td>18208</td>\n",
       "      <td>They were scheduled to fly from iraq to the un...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>David Zucchino</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>BAGHDAD  —   The Trump administration amended ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>17294</td>\n",
       "      <td>The decision they are making is not what does ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>John Schwartz</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>science</td>\n",
       "      <td>THOMPSONS, Tex.  —   Can one of the most promi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>259</td>\n",
       "      <td>18456</td>\n",
       "      <td>bruins goalie tim thomas declined to visit the...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Victor Mather</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>At least six members of the Super   New Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>259</td>\n",
       "      <td>18355</td>\n",
       "      <td>he would like to return to his country one day...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Emily Palmer</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>business</td>\n",
       "      <td>Driving down a tight mountain road in Jarabaco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     id                                      human_summary  \\\n",
       "308         259  17650  The thinking goes that some of the ancient ice...   \n",
       "772         259  18208  They were scheduled to fly from iraq to the un...   \n",
       "8             0  17294  The decision they are making is not what does ...   \n",
       "993         259  18456  bruins goalie tim thomas declined to visit the...   \n",
       "902         259  18355  he would like to return to his country one day...   \n",
       "\n",
       "        publication              author        date    year month  \\\n",
       "308  New York Times  Nicholas St. Fleur  2017-01-09  2017.0   1.0   \n",
       "772  New York Times      David Zucchino  2017-02-03  2017.0   2.0   \n",
       "8    New York Times       John Schwartz  2017-01-05  2017.0   1.0   \n",
       "993  New York Times       Victor Mather  2017-02-13  2017.0   2.0   \n",
       "902  New York Times        Emily Palmer  2017-02-07  2017.0   2.0   \n",
       "\n",
       "             theme                                            content  \n",
       "308  entertainment  Every Friday, we’ll offer a Trilobite talking ...  \n",
       "772       politics  BAGHDAD  —   The Trump administration amended ...  \n",
       "8          science  THOMPSONS, Tex.  —   Can one of the most promi...  \n",
       "993       politics  At least six members of the Super   New Englan...  \n",
       "902       business  Driving down a tight mountain road in Jarabaco...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle dataset download link\n",
    "# https://github.com/reddzzz/DataScience_FP/blob/main/dataset.xlsx\n",
    "\n",
    "dataset = pd.read_excel(r\"D:\\Datasets\\dataset.xlsx\")\n",
    "dataset = dataset.sample(frac=1)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9a0744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of summaries: 1168.78 characters\n"
     ]
    }
   ],
   "source": [
    "dataset['summary_length'] = dataset['human_summary'].apply(len)\n",
    "average_length = dataset['summary_length'].mean()\n",
    "print(f\"Average length of summaries: {average_length:.2f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb7b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(model, system_role, user_query):\n",
    "    \n",
    "    response = model.chat_completion(\n",
    "    messages=[{\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_query}],\n",
    "    max_tokens=1500,\n",
    "    )\n",
    "         \n",
    "    output = response.choices[0].message.content\n",
    "    summary = output.strip().split(\"\\n\")[-1].strip()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c8813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate ROUGE scores\n",
    "def calculate_rouge(reference, candidate):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    return {key: value.fmeasure for key, value in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad482ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article 1.\n",
      "Summarizing article 2.\n",
      "Summarizing article 3.\n",
      "Summarizing article 4.\n",
      "Summarizing article 5.\n",
      "Summarizing article 6.\n",
      "Summarizing article 7.\n",
      "Summarizing article 8.\n",
      "Summarizing article 9.\n",
      "Summarizing article 10.\n",
      "Summarizing article 11.\n",
      "Summarizing article 12.\n",
      "Summarizing article 13.\n",
      "Summarizing article 14.\n",
      "Summarizing article 15.\n",
      "Summarizing article 16.\n",
      "Summarizing article 17.\n",
      "Summarizing article 18.\n",
      "Summarizing article 19.\n",
      "Summarizing article 20.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "i = 0\n",
    "for _, row in dataset[:20].iterrows():\n",
    "    article = row['content']\n",
    "    human_summary = row['human_summary']\n",
    "    \n",
    "    i = i + 1\n",
    "        \n",
    "    print(f\"Summarizing article {i}.\")\n",
    "    system_role = \"You are an expert in creating summaries from text\"\n",
    "    user_query = f\"\"\"Summarize the following article in 1150 characters. Do not return your thought process. Only the summary.\n",
    "    Your summary will be evaluated using ROUGE score. The summary should look like human created:\\n\\n{article}\\n\\nSummary:\"\"\"\n",
    "\n",
    "    generated_summary = generate_summary(deepseek_model_client, \n",
    "                                         system_role, \n",
    "                                         user_query)\n",
    "    \n",
    "    rouge_scores = calculate_rouge(human_summary, generated_summary)\n",
    "\n",
    "    results.append({\n",
    "        'article_id': row.id,\n",
    "        'generated_summary': generated_summary,\n",
    "        'rouge1': rouge_scores['rouge1'],\n",
    "        'rouge2': rouge_scores['rouge2'],\n",
    "        'rougeL': rouge_scores['rougeL']\n",
    "    })\n",
    "\n",
    "# Create a DataFrame with results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b293f058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1    0.368321\n",
      "rouge2    0.102507\n",
      "rougeL    0.183425\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_values = results_df[['rouge1', 'rouge2', 'rougeL']].mean()\n",
    "print(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4696a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
